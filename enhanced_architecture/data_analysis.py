#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ•°æ®é›†åˆ†æè„šæœ¬
åˆ†æGram-å’ŒGram+-æ•°æ®é›†çš„å…³ç³»ï¼Œä¸ºå¯¹æ¯”å­¦ä¹ åšå‡†å¤‡
"""

import os
import pandas as pd
from collections import Counter
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def parse_fasta(file_path):
    """è§£æFASTAæ–‡ä»¶"""
    sequences = []
    headers = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        current_seq = ""
        current_header = ""
        
        for line in f:
            line = line.strip()
            if line.startswith('>'):
                if current_seq:
                    sequences.append(current_seq)
                    headers.append(current_header)
                current_header = line[1:]  # å»æ‰>
                current_seq = ""
            else:
                current_seq += line
        
        # æ·»åŠ æœ€åä¸€ä¸ªåºåˆ—
        if current_seq:
            sequences.append(current_seq)
            headers.append(current_header)
    
    return headers, sequences

def analyze_datasets():
    """åˆ†ææ•°æ®é›†"""
    # æ•°æ®è·¯å¾„
    gram_neg_path = "/Users/apple/AIBD/Gram-_Database/data/Gram-.fasta"        # åªæŠ—é˜´æ€§èŒ
    gram_both_path = "/Users/apple/AIBD/Gram-_Database/data/Gram+-.fasta"      # æ—¢æŠ—é˜³æ€§åˆæŠ—é˜´æ€§
    gram_pos_path = "/Users/apple/AIBD/Gram-_Database/data/Gram+.fasta"        # åªæŠ—é˜³æ€§èŒ
    
    logger.info("å¼€å§‹åˆ†æä¸‰ä¸ªæ•°æ®é›†...")
    
    # è§£ææ•°æ®
    headers_neg, seqs_neg = parse_fasta(gram_neg_path)
    headers_both, seqs_both = parse_fasta(gram_both_path)
    headers_pos, seqs_pos = parse_fasta(gram_pos_path)
    
    logger.info(f"Gram- (åªæŠ—é˜´æ€§èŒ): {len(seqs_neg)} æ¡åºåˆ—")
    logger.info(f"Gram+- (æ—¢æŠ—é˜³æ€§åˆæŠ—é˜´æ€§): {len(seqs_both)} æ¡åºåˆ—")
    logger.info(f"Gram+ (åªæŠ—é˜³æ€§èŒ): {len(seqs_pos)} æ¡åºåˆ—")
    
    # è½¬æ¢ä¸ºé›†åˆä¾¿äºåˆ†æ
    set_neg = set(seqs_neg)
    set_both = set(seqs_both)
    set_pos = set(seqs_pos)
    
    # åˆ†æé‡å æƒ…å†µ
    overlap_neg_both = set_neg.intersection(set_both)
    overlap_pos_both = set_pos.intersection(set_both)
    overlap_neg_pos = set_neg.intersection(set_pos)
    
    logger.info(f"\n=== æ•°æ®é›†é‡å åˆ†æ ===")
    logger.info(f"åªæŠ—é˜´æ€§èŒåºåˆ—: {len(set_neg)}")
    logger.info(f"å¹¿è°±æŠ—èŒåºåˆ—: {len(set_both)}")
    logger.info(f"åªæŠ—é˜³æ€§èŒåºåˆ—: {len(set_pos)}")
    logger.info(f"é˜´æ€§-å¹¿è°±é‡å : {len(overlap_neg_both)} ({len(overlap_neg_both)/len(set_neg)*100:.1f}%)")
    logger.info(f"é˜³æ€§-å¹¿è°±é‡å : {len(overlap_pos_both)} ({len(overlap_pos_both)/len(set_pos)*100:.1f}%)")
    logger.info(f"é˜´æ€§-é˜³æ€§é‡å : {len(overlap_neg_pos)} (åº”è¯¥ä¸º0)")
    
    # å¯¹æ¯”å­¦ä¹ æ•°æ®é›†æ„å»º
    # æ­£æ ·æœ¬ï¼šæ‰€æœ‰æŠ—é˜´æ€§èŒåºåˆ— (Gram- + Gram+-)
    positive_seqs = list(set_neg.union(set_both))
    
    # è´Ÿæ ·æœ¬ï¼šåªæŠ—é˜³æ€§èŒåºåˆ— (Gram+)
    negative_seqs = list(set_pos)
    
    logger.info(f"\n=== å¯¹æ¯”å­¦ä¹ æ•°æ®é›† ===")
    logger.info(f"æ­£æ ·æœ¬ï¼ˆæŠ—é˜´æ€§èŒï¼‰: {len(positive_seqs)} æ¡")
    logger.info(f"  - åªæŠ—é˜´æ€§: {len(set_neg)} æ¡")
    logger.info(f"  - å¹¿è°±æŠ—èŒ: {len(set_both)} æ¡")
    logger.info(f"è´Ÿæ ·æœ¬ï¼ˆåªæŠ—é˜³æ€§èŒï¼‰: {len(negative_seqs)} æ¡")
    logger.info(f"æ­£è´Ÿæ¯”ä¾‹: 1:{len(negative_seqs)/len(positive_seqs):.2f}")
    
    # åºåˆ—é•¿åº¦ç»Ÿè®¡
    len_neg = [len(seq) for seq in seqs_neg]
    len_both = [len(seq) for seq in seqs_both]
    len_pos = [len(seq) for seq in seqs_pos]
    
    logger.info(f"\n=== åºåˆ—é•¿åº¦ç»Ÿè®¡ ===")
    logger.info(f"åªæŠ—é˜´æ€§èŒå¹³å‡é•¿åº¦: {sum(len_neg)/len(len_neg):.1f} Â± {(sum([(x-sum(len_neg)/len(len_neg))**2 for x in len_neg])/len(len_neg))**0.5:.1f}")
    logger.info(f"å¹¿è°±æŠ—èŒå¹³å‡é•¿åº¦: {sum(len_both)/len(len_both):.1f} Â± {(sum([(x-sum(len_both)/len(len_both))**2 for x in len_both])/len(len_both))**0.5:.1f}")
    logger.info(f"åªæŠ—é˜³æ€§èŒå¹³å‡é•¿åº¦: {sum(len_pos)/len(len_pos):.1f} Â± {(sum([(x-sum(len_pos)/len(len_pos))**2 for x in len_pos])/len(len_pos))**0.5:.1f}")
    
    # æ°¨åŸºé…¸ç»„æˆåˆ†æ
    def get_aa_composition(sequences):
        all_aas = ''.join(sequences)
        total = len(all_aas)
        composition = Counter(all_aas)
        return {aa: count/total for aa, count in composition.items()}
    
    comp_pos = get_aa_composition(positive_seqs)  # æŠ—é˜´æ€§èŒ
    comp_neg = get_aa_composition(negative_seqs)  # åªæŠ—é˜³æ€§èŒ
    
    logger.info(f"\n=== æ°¨åŸºé…¸ç»„æˆå·®å¼‚ (Top 5) ===")
    logger.info("æŠ—é˜´æ€§èŒåºåˆ— vs åªæŠ—é˜³æ€§èŒåºåˆ—çš„ç»„æˆå·®å¼‚:")
    
    aa_diff = {}
    for aa in comp_pos:
        if aa in comp_neg:
            aa_diff[aa] = comp_pos[aa] - comp_neg[aa]
    
    # æ˜¾ç¤ºå·®å¼‚æœ€å¤§çš„æ°¨åŸºé…¸
    sorted_diff = sorted(aa_diff.items(), key=lambda x: abs(x[1]), reverse=True)[:5]
    for aa, diff in sorted_diff:
        logger.info(f"{aa}: æŠ—é˜´æ€§{comp_pos[aa]:.3f} vs åªæŠ—é˜³æ€§{comp_neg.get(aa, 0):.3f} (å·®å¼‚: {diff:+.3f})")
    
    # ä¿å­˜åˆ†æç»“æœ
    results = {
        'gram_neg_only': list(set_neg),          # åªæŠ—é˜´æ€§èŒ
        'gram_both': list(set_both),             # å¹¿è°±æŠ—èŒ
        'gram_pos_only': list(set_pos),          # åªæŠ—é˜³æ€§èŒ
        'positive_sequences': positive_seqs,      # å¯¹æ¯”å­¦ä¹ æ­£æ ·æœ¬
        'negative_sequences': negative_seqs,      # å¯¹æ¯”å­¦ä¹ è´Ÿæ ·æœ¬
        'stats': {
            'gram_neg_count': len(set_neg),
            'gram_both_count': len(set_both),
            'gram_pos_count': len(set_pos),
            'positive_count': len(positive_seqs),
            'negative_count': len(negative_seqs),
            'pos_neg_ratio': len(negative_seqs)/len(positive_seqs)
        }
    }
    
    return results

def create_training_datasets(results):
    """åˆ›å»ºè®­ç»ƒæ•°æ®é›†"""
    logger.info("\n=== åˆ›å»ºè®­ç»ƒæ•°æ®é›† ===")
    
    # æ­£æ ·æœ¬ï¼šæ‰€æœ‰æŠ—é©å…°æ°é˜´æ€§èŒåºåˆ— (Gram- + Gram+-)
    positive_seqs = results['positive_sequences']
    
    # è´Ÿæ ·æœ¬ï¼šåªæŠ—é˜³æ€§èŒåºåˆ— (Gram+)
    negative_seqs = results['negative_sequences']
    
    # ä¸»è®­ç»ƒé›†ï¼šåªç”¨Gram-åºåˆ—è¿›è¡Œdiffusionè®­ç»ƒ
    main_training_seqs = results['gram_neg_only']
    
    logger.info(f"ä¸»è®­ç»ƒé›†ï¼ˆåªæŠ—é˜´æ€§èŒï¼‰: {len(main_training_seqs)} æ¡")
    logger.info(f"æ­£æ ·æœ¬ï¼ˆæ‰€æœ‰æŠ—é˜´æ€§èŒï¼‰: {len(positive_seqs)} æ¡")
    logger.info(f"è´Ÿæ ·æœ¬ï¼ˆåªæŠ—é˜³æ€§èŒï¼‰: {len(negative_seqs)} æ¡")
    logger.info(f"æ­£è´Ÿæ¯”ä¾‹: 1:{len(negative_seqs)/len(positive_seqs):.2f}")
    
    # ä¿å­˜è®­ç»ƒé›†
    with open('/Users/apple/AIBD/Gram-_Database/enhanced_architecture/main_training_sequences.txt', 'w') as f:
        for seq in main_training_seqs:
            f.write(seq + '\n')
    
    with open('/Users/apple/AIBD/Gram-_Database/enhanced_architecture/positive_sequences.txt', 'w') as f:
        for seq in positive_seqs:
            f.write(seq + '\n')
    
    with open('/Users/apple/AIBD/Gram-_Database/enhanced_architecture/negative_sequences.txt', 'w') as f:
        for seq in negative_seqs:
            f.write(seq + '\n')
    
    # é¢å¤–ä¿å­˜ä¸‰ä¸ªåŸå§‹æ•°æ®é›†
    with open('/Users/apple/AIBD/Gram-_Database/enhanced_architecture/gram_neg_only.txt', 'w') as f:
        for seq in results['gram_neg_only']:
            f.write(seq + '\n')
    
    with open('/Users/apple/AIBD/Gram-_Database/enhanced_architecture/gram_both.txt', 'w') as f:
        for seq in results['gram_both']:
            f.write(seq + '\n')
    
    with open('/Users/apple/AIBD/Gram-_Database/enhanced_architecture/gram_pos_only.txt', 'w') as f:
        for seq in results['gram_pos_only']:
            f.write(seq + '\n')
    
    logger.info("è®­ç»ƒæ•°æ®é›†å·²ä¿å­˜åˆ° enhanced_architecture/ ç›®å½•")
    logger.info("æ–‡ä»¶åˆ—è¡¨:")
    logger.info("  - main_training_sequences.txt: ä¸»è®­ç»ƒé›†ï¼ˆåªæŠ—é˜´æ€§èŒï¼‰")
    logger.info("  - positive_sequences.txt: å¯¹æ¯”å­¦ä¹ æ­£æ ·æœ¬ï¼ˆæ‰€æœ‰æŠ—é˜´æ€§èŒï¼‰")
    logger.info("  - negative_sequences.txt: å¯¹æ¯”å­¦ä¹ è´Ÿæ ·æœ¬ï¼ˆåªæŠ—é˜³æ€§èŒï¼‰")
    
    return main_training_seqs, positive_seqs, negative_seqs

if __name__ == "__main__":
    # åˆ†ææ•°æ®é›†
    results = analyze_datasets()
    
    # åˆ›å»ºè®­ç»ƒæ•°æ®é›†
    main_seqs, positive_seqs, negative_seqs = create_training_datasets(results)
    
    logger.info("\nâœ… æ•°æ®åˆ†æå®Œæˆï¼")
    logger.info("\n=== æ¨èçš„è®­ç»ƒç­–ç•¥ ===")
    logger.info(f"ğŸ¯ ä¸»è·¯å¾„(Diffusion): ä½¿ç”¨{len(main_seqs)}æ¡åªæŠ—é˜´æ€§èŒåºåˆ—")
    logger.info(f"ğŸ”„ è¾…åŠ©è·¯å¾„(ESM-2): å¯¹æ¯”å­¦ä¹ ")
    logger.info(f"   â”œâ”€ æ­£æ ·æœ¬: {len(positive_seqs)}æ¡æŠ—é˜´æ€§èŒåºåˆ—")
    logger.info(f"   â””â”€ è´Ÿæ ·æœ¬: {len(negative_seqs)}æ¡åªæŠ—é˜³æ€§èŒåºåˆ—")
    logger.info(f"ğŸ“Š æ•°æ®æ„æˆ:")
    logger.info(f"   â”œâ”€ åªæŠ—é˜´æ€§èŒ: {results['stats']['gram_neg_count']}æ¡")
    logger.info(f"   â”œâ”€ å¹¿è°±æŠ—èŒ: {results['stats']['gram_both_count']}æ¡")
    logger.info(f"   â””â”€ åªæŠ—é˜³æ€§èŒ: {results['stats']['gram_pos_count']}æ¡")
