#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®å¤åçš„æ‰©æ•£æ¨¡å‹
éªŒè¯PAD tokenå¤„ç†æ˜¯å¦æ­£ç¡®
"""

import torch
import numpy as np
from data_loader import sequence_to_tokens, tokens_to_sequence, AMINO_ACID_VOCAB
from diffusion_models.d3pm_diffusion import D3PMDiffusion, D3PMScheduler, D3PMUNet

def test_fixed_diffusion():
    """æµ‹è¯•ä¿®å¤åçš„æ‰©æ•£æ¨¡å‹"""
    print("ğŸ§ª æµ‹è¯•ä¿®å¤åçš„æ‰©æ•£æ¨¡å‹...")
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cpu")
    vocab_size = len(AMINO_ACID_VOCAB)
    
    # åˆ›å»ºæ¨¡å‹ç»„ä»¶
    scheduler = D3PMScheduler(num_timesteps=100, vocab_size=vocab_size)
    unet = D3PMUNet(vocab_size=vocab_size, hidden_dim=128, num_layers=4, 
                    max_seq_len=50)
    diffusion = D3PMDiffusion(unet, scheduler, device)
    
    print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ (vocab_size: {vocab_size})")
    
    # æµ‹è¯•æ•°æ®ï¼šä¸€äº›ç®€å•çš„æ°¨åŸºé…¸åºåˆ—
    test_sequences = [
        "ARNDCQEGHILKMFPSTWYV",  # åŒ…å«æ‰€æœ‰æ°¨åŸºé…¸
        "KKLLKWLLKLL",           # å¸¸è§çš„æŠ—èŒè‚½æ¨¡å¼
        "GGGPPPGGG",             # ç®€å•é‡å¤æ¨¡å¼
        "ACDEFGHIK",             # çŸ­åºåˆ—
    ]
    
    # è½¬æ¢ä¸ºtokens
    max_len = 30
    test_tokens = []
    for seq in test_sequences:
        tokens = sequence_to_tokens(seq, max_len)
        test_tokens.append(tokens)
    
    x_batch = torch.stack(test_tokens)
    print(f"âœ“ æµ‹è¯•æ•°æ®å‡†å¤‡å®Œæˆ: {x_batch.shape}")
    
    # æ£€æŸ¥PAD tokenåˆ†å¸ƒ
    pad_count = (x_batch == 0).sum().item()
    total_tokens = x_batch.numel()
    pad_ratio = pad_count / total_tokens
    print(f"  - PAD tokenæ¯”ä¾‹: {pad_ratio:.2%} ({pad_count}/{total_tokens})")
    
    # æµ‹è¯•å‰å‘æ‰©æ•£è¿‡ç¨‹
    print("\nğŸ”„ æµ‹è¯•å‰å‘æ‰©æ•£è¿‡ç¨‹...")
    t = torch.randint(0, scheduler.num_timesteps, (len(test_sequences),))
    x_noisy = scheduler.q_sample(x_batch, t)
    
    # æ£€æŸ¥å™ªå£°ä¸­çš„PAD token
    noisy_pad_count = (x_noisy == 0).sum().item()
    noisy_pad_ratio = noisy_pad_count / total_tokens
    print(f"  - åŠ å™ªåPAD tokenæ¯”ä¾‹: {noisy_pad_ratio:.2%} ({noisy_pad_count}/{total_tokens})")
    
    # éªŒè¯PADä½ç½®æ˜¯å¦ä¿æŒä¸å˜
    original_pad_mask = (x_batch == 0)
    noisy_pad_preserved = (x_noisy[original_pad_mask] == 0).all()
    print(f"  - PADä½ç½®ä¿æŒä¸å˜: {'âœ“' if noisy_pad_preserved else 'âŒ'}")
    
    # æµ‹è¯•æŸå¤±è®¡ç®—
    print("\nğŸ“Š æµ‹è¯•æŸå¤±è®¡ç®—...")
    try:
        loss = diffusion.training_loss(x_batch)
        print(f"  - è®­ç»ƒæŸå¤±: {loss.item():.4f}")
        print("  - æŸå¤±è®¡ç®—æˆåŠŸ âœ“")
    except Exception as e:
        print(f"  - æŸå¤±è®¡ç®—å¤±è´¥ âŒ: {e}")
        return False
    
    # æµ‹è¯•é‡‡æ ·è¿‡ç¨‹
    print("\nğŸ² æµ‹è¯•é‡‡æ ·è¿‡ç¨‹...")
    try:
        # ç”Ÿæˆåºåˆ—
        generated = diffusion.sample(batch_size=2, seq_len=20, num_inference_steps=10)
        print(f"  - ç”Ÿæˆåºåˆ—shape: {generated.shape}")
        
        # æ£€æŸ¥ç”Ÿæˆçš„token
        unique_tokens = torch.unique(generated)
        print(f"  - ç”Ÿæˆçš„unique tokens: {unique_tokens.tolist()}")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«PAD token
        contains_pad = (generated == 0).any()
        print(f"  - åŒ…å«PAD token: {'âŒ' if contains_pad else 'âœ“'}")
        
        # è½¬æ¢ä¸ºåºåˆ—
        generated_sequences = []
        for i in range(generated.shape[0]):
            seq = tokens_to_sequence(generated[i])
            generated_sequences.append(seq)
            print(f"  - åºåˆ—{i+1}: '{seq}' (é•¿åº¦: {len(seq)})")
        
        # æ£€æŸ¥åºåˆ—æœ‰æ•ˆæ€§
        valid_sequences = [seq for seq in generated_sequences if len(seq) > 0]
        valid_ratio = len(valid_sequences) / len(generated_sequences)
        print(f"  - æœ‰æ•ˆåºåˆ—æ¯”ä¾‹: {valid_ratio:.1%} ({len(valid_sequences)}/{len(generated_sequences)})")
        
        if valid_ratio > 0:
            print("  - åºåˆ—ç”ŸæˆæˆåŠŸ âœ“")
            return True
        else:
            print("  - åºåˆ—ç”Ÿæˆå¤±è´¥ âŒ")
            return False
            
    except Exception as e:
        print(f"  - é‡‡æ ·è¿‡ç¨‹å¤±è´¥ âŒ: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ”§ æ‰©æ•£æ¨¡å‹ä¿®å¤éªŒè¯æµ‹è¯•")
    print("=" * 60)
    
    success = test_fixed_diffusion()
    
    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ æµ‹è¯•é€šè¿‡ï¼æ‰©æ•£æ¨¡å‹ä¿®å¤æˆåŠŸ")
        print("ğŸ’¡ ç°åœ¨å¯ä»¥å¼€å§‹é‡æ–°è®­ç»ƒæ¨¡å‹")
        print("âš¡ ä½¿ç”¨å‘½ä»¤: python3 start_training.py --config quick_test")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
    print("=" * 60)

if __name__ == "__main__":
    main()
